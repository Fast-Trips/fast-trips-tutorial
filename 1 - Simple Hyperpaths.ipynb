{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 - Hyperpath-Based Path-Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define A Simple Network with Competing Options\n",
    "\n",
    "\n",
    "B\t---\t----\t-->\tD    \n",
    "B\t-->\tC\t-->\tD    \n",
    "\t\tC\t-->\tD    \n",
    "        C\t-->\tD    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=[{'A':'orig','B':'b','name':'access' , 'IVT':0  ,  'xfers': 0},\n",
    " {'A':'c','B':'d', 'name':'cd1', 'IVT':8  ,  'xfers': 0},\n",
    " {'A':'c','B':'d', 'name':'cd2', 'IVT':10  ,  'xfers': 0},\n",
    " {'A':'c','B':'d', 'name':'cd3', 'IVT':30 ,  'xfers': 0},\n",
    " {'A':'b','B':'c', 'name':'bc' , 'IVT':3  ,  'xfers': 1},\n",
    " {'A':'b','B':'d', 'name':'bd' , 'IVT':15  ,  'xfers': 0},\n",
    " {'A':'d','B':'dest','name':'egress' , 'IVT':0  ,  'xfers': 0},\n",
    "]\n",
    "\n",
    "n_df = pd.DataFrame(n)\n",
    "\n",
    "pos_df = pd.DataFrame([['orig',0,0],\n",
    "                      ['b',1,0],\n",
    "                      ['c',3,-.5],\n",
    "                      ['d',5,0],\n",
    "                      ['dest',6,0]], columns = ['N','x','y'])\n",
    "#n_df, pos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Examine Network to Make Sure it is what you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_link(row):\n",
    "    import math\n",
    "    r=200\n",
    "    ##TODO calculate x and Y based on arcs based on how many links are overlapping\n",
    "    ##...or just offset a convenient number\n",
    "    x_coords = np.linspace(row[\"Ax\"],row[\"Bx\"], 50)\n",
    "    ys = np.linspace(row[\"Ay\"],row[\"By\"], 50)\n",
    "    y_coords = [(1/r)*math.sin(r*y) for y in ys]\n",
    "    #y_coords = np.linspace(row[\"Ay\"],row[\"By\"], 50)\n",
    "    return x_coords, y_coords\n",
    "\n",
    "net_df=n_df.merge(pos_df,left_on=['A'],right_on=['N'],how='left')\n",
    "net_df.rename(columns={\"x\":\"Ax\",\"y\":\"Ay\"}, inplace=True)\n",
    "net_df=net_df.merge(pos_df,left_on=['B'],right_on=['N'],how='left')\n",
    "net_df.rename(columns={\"x\":\"Bx\",\"y\":\"By\"}, inplace=True)\n",
    "\n",
    "net_df['link_x'], net_df['link_y'] = zip(*net_df.apply(make_link, axis=1))\n",
    "\n",
    "#print(net_df)\n",
    "def plot_network(nodes_df,links_df):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    \n",
    "    #nodes\n",
    "    ax1 = sns.pointplot(x='x', y='y', hue='N',data=nodes_df)\n",
    "    \n",
    "    #links\n",
    "    ##TODO - fix these links to not be offset\n",
    "    for index, row in net_df.iterrows():\n",
    "        plt.plot(row['link_x'], row['link_y'])\n",
    "        \n",
    "    ##TODO - add in labels for links and values like IVT, etc.\n",
    "    ax1.set_title(\"Network\")\n",
    "    ax1.set_ylim(-5,5)\n",
    "    plt.show()\n",
    "    \n",
    "plot_network(pos_df,n_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Parameters and Variables\n",
    "\n",
    " * Coefficients on variables\n",
    " * Dispersion Paramter, Theta\n",
    " * Direction on SP (Backward SP is the one currently implemented)\n",
    " * Start and End Nodes\n",
    " * Initial Labels \n",
    " * Scan-eligible queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C_IVT = -.1\n",
    "C_xfer= C_IVT*15\n",
    "THETA = 0.5\n",
    "\n",
    "BEGIN = 'dest'\n",
    "END   = 'orig' \n",
    "FORWARD = False     #TODO implement forward SP\n",
    "INIT_LABEL = -9999  #should be same sign as the C_IVT\n",
    "\n",
    "current_node   = BEGIN\n",
    "n_df['label_j']= INIT_LABEL\n",
    "n_df['label_i']= INIT_LABEL\n",
    "\n",
    "# Initialize labels of starting node to zero\n",
    "if FORWARD:\n",
    "    n_df.loc[n_df['A']==current_node,'label_i'] = 0\n",
    "elif not FORWARD:\n",
    "    n_df.loc[n_df['B']==current_node,'label_j'] = 0\n",
    "\n",
    "# Calculate link-based utility\n",
    "n_df['u_link']=(C_IVT*n_df['IVT']) + (C_xfer*n_df['xfers'])\n",
    "\n",
    "# Initialize the queue of nodes(stops) to be examined\n",
    "import queue\n",
    "scan_eligible = queue.PriorityQueue()\n",
    "scan_eligible.put((0,current_node))\n",
    "\n",
    "#store results of each step in df\n",
    "df_iters = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions\n",
    "\n",
    "  * Logsum Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_logsum(net_df, current_node, theta, forward = False, flag_positive = True, flag_negative = False):\n",
    "    '''\n",
    "    Calculates and returns logsum of the labels of the predecessor links.\n",
    "    *net_df* is a pandas dataframe of the network\n",
    "    *current_node* is the name node that the logsum is being calculated for\n",
    "    *theta* is the dispersion parameter\n",
    "    *forward* is a boolean value to flag whether the shortest path is forward or backward\n",
    "    *flag_positive* is a boolean. If the labels are based on utilities, the logsum should always be negative.  \n",
    "    *flag_negative* is a boolean. If the labels are based on costs, the logsum value should be negative.  \n",
    "    '''\n",
    "\n",
    "    if forward: \n",
    "        predecessor_node = 'B'\n",
    "        predecessor_label = 'label_j'\n",
    "        print(\"Calculating Forward SP Logsum\")\n",
    "    else:\n",
    "        predecessor_node = 'A'\n",
    "        predecessor_label = 'label_i'\n",
    "        print(\"Calculating Backward SP Logsum\")\n",
    "    \n",
    "    ## Exponentiate the label from the predecessor link\n",
    "    print(\"Using these links: \",list(net_df[n_df[predecessor_node]==current_node]['name']))\n",
    "    n_df.loc[n_df[predecessor_node]==current_node,'exp_label'] = np.exp((1/theta)*n_df.loc[n_df[predecessor_node]==current_node,predecessor_label])\n",
    "\n",
    "    ## Logsum of exponentiated labels of predecessor links\n",
    "    logsum = theta*np.log(np.sum(n_df.loc[n_df[predecessor_node] == current_node,'exp_label']))\n",
    "    print(\"Logsum: \", logsum)\n",
    "    \n",
    "    if flag_positive and logsum>0:\n",
    "        print(\"FLAG POSITIVE\")\n",
    "    \n",
    "    if flag_negative and logsum>0:\n",
    "        print(\"FLAG NEGATIVE\")\n",
    "        \n",
    "    return logsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backwards Hyperpath Calculation Algorithm\n",
    "\n",
    "Calculates hyperlink utilities weighted based on log-sum formulations.\n",
    "\n",
    " * Implemented for very simple network of links and nodes.  \n",
    " * Does not consider transfer times.  \n",
    " * Does not consider timing, preferred arrival/departure times.  \n",
    " * Does not consider fares.  \n",
    "\n",
    "**TODO** \n",
    "\n",
    " * Implement true version of scan eligible list  \n",
    " * Calculate Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_sp(n_df,scan_eligible,theta, steps_df = True):\n",
    "    step = 0\n",
    "    steps = []\n",
    "    while not scan_eligible.empty():\n",
    "        step += 1\n",
    "        \n",
    "        current_node = scan_eligible.get()[1]\n",
    "        print(\"---Current node: \", current_node)\n",
    "        \n",
    "        \n",
    "        # update label based on labels predecessors (if there are any), store in label_j\n",
    "        logsum=-99999\n",
    "        if not n_df[n_df['A']==current_node].empty:  \n",
    "            logsum = calculate_logsum(n_df, current_node, theta, forward=False)\n",
    "            n_df.loc[n_df['B']==current_node,'label_j'] = logsum\n",
    "            \n",
    "        # label at predecessor node should be the label at current node + link cost\n",
    "        n_df.loc[n_df['B']==current_node,'label_i'] = n_df.loc[n_df['B']==current_node,'label_j'] + n_df.loc[n_df['B']==current_node,'u_link']\n",
    "        #print(n_df)\n",
    "        \n",
    "        pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
    "\n",
    "        # store the results of this iteration if desired\n",
    "        if steps_df:\n",
    "            steps.append([step, current_node,logsum])\n",
    "            df_iters[step] = n_df.copy(deep=True)\n",
    "            \n",
    "        # add nodes to scan-eligible and prioritize based on label\n",
    "        ## TODO make this real\n",
    "        if current_node == 'dest': scan_eligible.put((0,'d'))\n",
    "        if current_node == 'd': \n",
    "            scan_eligible.put((1,'c'))\n",
    "            scan_eligible.put((2,'b'))\n",
    "            \n",
    "    if steps_df:\n",
    "        return pd.DataFrame(steps, columns=['step','current_node','logsum'])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_df = backward_sp(n_df,scan_eligible,THETA, steps_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Hyperpath Algorithm's Process\n",
    "\n",
    "  * all logums should be the sign of the C_IVT coefficient\n",
    "  * All labels should be \"improving\" for each node for each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rehape Iters_DF\n",
    "iters_df=pd.concat(df_iters,axis=0)\n",
    "iters_df.index.names = ['step', 'link_num']\n",
    "iters_df.reset_index(inplace=True)  \n",
    "#iters_df\n",
    "\n",
    "steps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logsums_each_step(steps_df):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax3 = sns.pointplot(x='step', y='logsum', hue='current_node',data=steps_df)\n",
    "    ax3.set_title(\"Logsums by Node\")\n",
    "    ax3.set_ylim(-5,5)\n",
    "    plt.show()\n",
    "plot_logsums_each_step(steps_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_style(\"whitegrid\")\n",
    "def plot_labels_by_step(iters_df):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax3 = sns.pointplot(x='step', y='label_i', hue='name',data=iters_df)\n",
    "    ax3.set_title(\"Label i over each step\")\n",
    "    ax3.grid(b=True, which='major', color='#d3d3d3', linewidth=1.0)\n",
    "    ax3.grid(b=True, which='minor', color='#d3d3d3', linewidth=0.5)\n",
    "    ax3.set_ylim(-5,5)\n",
    "    plt.show()\n",
    "plot_labels_by_step(iters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FT35]",
   "language": "python",
   "name": "conda-env-FT35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
